---
title: "Análise de series temporais"
subtitle: "Disciplina: Métodos Estatísticos de Previsão"
author: "Rafael Sebastião Arocho e Márcio Antonio Vieira"
institute: "Universidade Federal de Minas Gerais" 
date: last-modified
date-format: "DD/MM/YYYY"
lang: pt-br
format: pdf
---

{{< pagebreak >}}

```{r}
#| include: false
#| label: importando bibliotecas

if (!require("pacman")) install.packages("pacman")

pacman::p_load(dplyr, readr, 
  gtsummary, broom, 
  gt, ggplot2, 
  forecast, lubridate, 
  tsibble, fpp3, 
  feasts, fable,
  stringr, ggtime
)

dados <- as_tibble(read.csv("dados/ma_lga_12345.csv")) |> mutate(trimestre = dmy(saledate) |> yearquarter())
```

## Visão Geral dos Dados

Para esta análise, utilizamos o dataset ***House Property Sales Time Series***.

-   **Fonte dos dados:** [Kaggle.](https://www.kaggle.com/datasets/htagholdings/property-sales?select=ma_lga_12345.csv)

-   **Período:** 2007 a 2019

-   **Frequência:** Trimestral ($n = 347$ observações)

-   **Variável Resposta (**$Y_t$):

    -   *MA*: Preço (\$) mediano de casas e unidades habitacionais

```{r}
#| echo: false
#| label: tbl-resumo-serie
#| tbl-cap: 
#|  - resumo dos dados tbl1
#|  - resumo dos dados tbl2
#| tbl-column: page
#| layout-nrow: 2

dados_parte1 <- dados |>
  filter(bedrooms %in% c(1, 2, 3))

dados_parte2 <- dados |>
  filter(bedrooms %in% c(4, 5))

# Tabela 1
dados_parte1 |>
  tbl_summary(include=c("MA", "type", "bedrooms"), by=bedrooms, missing="no") |>
  add_n() |>
  add_overall()

# Tabela 2
dados_parte2 |>
  tbl_summary(include=c("MA", "type", "bedrooms"), by=bedrooms, missing="no") |>
  add_n() |>
  add_overall()
```

{{< pagebreak >}}

## Visualização da Série

```{r}
#| label: "gráfico da série"
#| echo: false
#| fig-cap: "distribuições das series"
#| fig-subcap:
#|   - "serie completa"
#|   - "serie decomposta"
#| fig-column: page
#| layout-ncol: 2

serie_temporal <- as_tsibble(dados |> select(-saledate), index=trimestre, key=c(type,bedrooms))

serie_temporal |> index_by(trimestre) |> summarise(median_MA = median(MA)) |> autoplot(median_MA) + 
  labs(title="Preço mediano da série agregada", y="Preço Mediano")

serie_temporal |>
  autoplot(MA) +
  labs(title = "Preço Mediano por Tipo e Número de Quartos", y = "Preço Mediano")

#separação em treino e teste
teste <- serie_temporal |> group_by(type, bedrooms) |> slice_tail(n = 6)
treino <- serie_temporal |>  group_by(type, bedrooms) |> slice_head(n = -6)
```

Observamos que será necessário separar as series em tipo de moradia e número de quartos para simplificar o ajuste. \
Parece haver tendência de crescimento em praticamente todas as séries decompostas.\
Vamos utilizar diferenciação de nível um e dois para ter outro olhar sobre as séries.

```{r}
#| echo: false
#| fig-cap: comportamentos diferenciados
#| fig-subcap: 
#|  - "diferenciação de primeiro nível"
#|  - "diferenciação de segundo nível"
#| fig-column: page

plot_transformed_diff_series <- function(data, var_name, diff) {
  
  # 2. Aplicar a transformação e a diferenciação
  transformed_data <- data |>
    # Agrupar para que as operações ocorram por grupo
    group_by(type, bedrooms) |>
    
    # Aplicar a diferenciação
    mutate(
      transformed_diff = difference(
        {{var_name}}, 
        lag = 1,
        differences=diff
      )
    ) |>
    ungroup()
  
  # 3. Plotar os resultados em um painel
  p <- transformed_data |>
    ggplot(aes(x = trimestre, y = transformed_diff)) +
    geom_line() +
    # Cria um gráfico separado para cada combinação
    facet_wrap(vars(type, bedrooms), scales = "free_y") +
    labs(
      title = str_glue("Séries  d={diff}", diff=diff),
      y = "Valor Diferenciado",
      x = "Trimestre"
    ) +
    theme_minimal()
  
  return(p)
}

plot_transformed_diff_series(treino, MA, 1)
plot_transformed_diff_series(treino, MA, 2)
```

Observando as séries com as diferenciações aplicadas vamos seguir a análise com os preços de diferentes combinações de tipo de domicilio e número de quartos.

```{r}
#| label: analise casa 2 quartos e apartamentos 5 quartos
#| include: false

plot_acf_pacf <- function(data, type, bedrooms, difference){
  serie <- data |> filter(type=={{type}}, bedrooms == {{bedrooms}})
  
  #aplicação da diferenciação de ordem {{difference}}
  if({{difference}} != 0){
    serie <- serie |> 
      mutate(MA = difference(MA, order_by=trimestre, lag=4, difference={{difference}}))}
  
  #graficos de ACF e PACF
  acf <- serie |> ACF(MA) |> autoplot() + 
    labs(title = "Autocorrelações", 
         subtitle = str_glue("type:{type}\n bedrooms: {bedrooms}", type=type, bedrooms=bedrooms))
  pacf <- serie |> PACF(MA) |> autoplot() + 
    labs(title= "Autocorrelações parciais", 
         subtitle = str_glue("type:{type}\n bedrooms: {bedrooms}", type=type, bedrooms=bedrooms))
  
  return(c(acf, pacf))
}
```

{{< pagebreak >}} \## Ajuste de modelos

### type=house x bedrooms=5

Para a série de type: *house* e 5 quartos testamos diferenciação para tornar a serie estacionária.

```{r}
#| label: "acf_pacf primeiro modelo"
#| fig-cap:
#|  - ACF
#|  - PACF
an_1 <- plot_acf_pacf(data=treino, type="house", bedrooms=5, difference=1)
an_1
an_2 <- plot_acf_pacf(data=treino, type="house", bedrooms=5, difference=2)
an_2
```

Parecemos ter um comportamento de ondas senóides no gráfico de ACF e um comportamento irregular no PACF que pode indicar sazonalidade. Vamos ajustar de ínicio um modelo ARIMA(2, 1, 0).\
Após o ajuste inicial faremos a sobrefixação dos modelos para identificar o melhor modelo através da avaliação das métricas de AIC

```{r}
#| title: ajuste do primeiro modelo ARIMA
#| echo: false

treino_casa_5 <- treino |> filter(type=="house", bedrooms == 5)
teste_casa_5 <- teste |> filter(type=="house", bedrooms == 5)


modelo_arima_1 <- treino_casa_5 |> 
  model(ARIMA(MA ~ pdq(2,1,0) + PDQ(0,0,0)))
tidy(modelo_arima_1)
aic_modelo_base <- modelo_arima_1 |> glance() |> pull(AIC)

modelo_arima_2 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(1,1,0) + PDQ(0,0,0)))
tidy(modelo_arima_2)
aic_modelo_2 <- modelo_arima_2 |> glance() |> pull(AIC)

modelo_arima_3 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(1,1,1) + PDQ(0,0,0)))
tidy(modelo_arima_3)
aic_modelo_3 <- modelo_arima_3 |> glance() |> pull(AIC)

modelo_arima_4 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(1,2,0) + PDQ(0,0,0)))
tidy(modelo_arima_4)
aic_modelo_4 <- modelo_arima_4 |> glance() |> pull(AIC)

modelo_arima_5 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(2,2,0) + PDQ(0,0,0)))
tidy(modelo_arima_5)
aic_modelo_5 <- modelo_arima_5 |> glance() |> pull(AIC)

modelo_arima_6 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(0,2,1) + PDQ(0,0,1)))
tidy(modelo_arima_6)
aic_modelo_6 <- modelo_arima_6 |> glance() |> pull(AIC)

modelo_arima_7 <- treino_casa_5 |> model(ARIMA(MA ~ pdq(1,2,1) + PDQ(0,0,1)))
tidy(modelo_arima_7)
aic_modelo_7 <- modelo_arima_7 |> glance() |> pull(AIC)
```

Ajustados os modelos daremos sequência na análise com o modelo ARIMA(0,2,1)(0,0,1)[4] por ter apresentado significância nos parâmetros e o menor dos valores de AIC

```{r}
ggtime::gg_tsresiduals(modelo_arima_6)
residuals(modelo_arima_6) |> 
  ggplot(mapping=aes(x=trimestre, y=.resid)) + 
  geom_jitter() +
  theme_minimal()

shapiro.test(residuals(modelo_arima_6)$.resid)
Box.test(residuals(modelo_arima_6)$.resid, lag=12)
```

Os testes nos mostram que os residuos apresentam normalidade e o teste de box-pierce não rejeita a hipótese de independencia, o que é um indicador que o ajuste está adequado.

Vamos fazer uma previsão alguns passos a frente

```{r}
forecast(modelo_arima_6, h=6) |> 
  autoplot(bind_rows(treino_casa_5, teste_casa_5)) + 
  labs(title = "ARIMA(0,2,1)(0,0,1)[4]") +
  theme_minimal()
```

#### Modelo de alisamento exponencial

Seguindo a mesma lógica dos ajustes anteriores faremos o ajuste de modelo de alisamento exponencial. Por não termos identificado sazonalidade utilizaremos alisamento exponencial de Holt-Winters aditivo por haver tendência e sazonalidade na série

```{r}

ma <-  ts(treino_casa_5$MA, start = c(2007, 3), frequency = 4)

AEH <- HoltWinters(ma, alpha = NULL, beta = NULL, gamma = TRUE, seasonal = "additive")
# Calculo das previsoes 6 passos a frente e os intervalos de previsao
previsao = predict(AEH, 
                   n.ahead=6, 
                   prediction.interval = TRUE, 
                   level = 0.95, 
                   interval="prediction") 
previsao

# Constroi o grafico com ajuste, previsoes e intervalos de previsao
plot(AEH, previsao, lwd=2, col="black", xlab="Ano", ylab=NA)
```

Faremos agora a comparação dos dois modelos utilizando erro quadrático médio

```{r}
# As previsões pontuais são a primeira coluna da matriz de previsão:
previsoes_pontuais_hw <- previsao[,"fit"]
previsoes_pontuais_arima <- forecast(modelo_arima_6, h=6)$.mean
valores_reais <- teste_casa_5$MA

# Cálculo do Erro Quadrático Médio (MSE)
erros_hw <- previsoes_pontuais_hw - valores_reais
erros_arima <- previsoes_pontuais_arima - valores_reais
MSE_hw <- mean(erros_hw^2)
MSE_arima <- mean(erros_arima^2)
cat("\nPrevisões Pontuais HW:\n")
print(previsoes_pontuais_hw)
cat("\nPrevisões Pontuais ARIMA:\n")
print(previsoes_pontuais_arima)
cat("\nValores Reais (Base de Teste):\n")
print(valores_reais)
cat("\nErro Quadrático Médio (MSE) para os 6 passos HW:\n")
print(MSE_hw)

cat("\nErro Quadrático Médio (MSE) para os 6 passos ARIMA:\n")
print(MSE_arima)
```

Observamos um EQM menor no ajuste com o modelo ARIMA, então podemos concluir que se trata do melhor modelo para ajustar a série de preços medianos de casas com 5 quartos.